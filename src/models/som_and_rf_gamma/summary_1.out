================================================================================
                               SOM and Random Forest Model                        
================================================================================

Using training file: /Users/chancehaycock/dev/machine_learning/px402/src/models/som_and_rf_gamma/train.csv

Using nested cross validation...
Outer Loop (Model Performance Estimation) using 5 folds. Random State: 123
Inner Loop (Hyper-parameter optimisation) using 5 folds. Random State: 123

Using 22 features:

Period_1
Period_2
amp_ratio_21
abs_magnitude
bp_rp
bp_g
g_rp
lc_amplitude
p2p_98
p2p_mean
stddev
kurtosis
skew
iqr
mad
max_binned_p2p
mean_binned_p2p
RRab_dist
EA_dist
EB_dist
GDOR_DSCUT_dist
template_dist

Inner loop is optimising over parameter space:
{'n_estimators': [300], 'min_samples_split': [3], 'max_features': [4]}


Best Parameters for outer loop 0: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}

Report:
              precision    recall  f1-score   support

       DSCUT       0.93      0.88      0.90        42
          EA       0.79      0.87      0.83        31
          EB       0.74      0.92      0.82        38
        GDOR       1.00      0.63      0.78        30
       Noise       0.91      1.00      0.95        91
      OTHPER       1.00      0.95      0.97       112
        RRab       1.00      0.93      0.96        28

    accuracy                           0.92       372
   macro avg       0.91      0.88      0.89       372
weighted avg       0.93      0.92      0.92       372

Best Parameters for outer loop 1: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}

Report:
              precision    recall  f1-score   support

       DSCUT       0.84      0.50      0.63        42
          EA       0.52      0.81      0.63        31
          EB       0.84      0.95      0.89        38
        GDOR       0.89      0.53      0.67        30
       Noise       0.87      0.82      0.85        91
      OTHPER       0.90      0.99      0.94       112
        RRab       0.93      0.96      0.95        28

    accuracy                           0.84       372
   macro avg       0.83      0.80      0.79       372
weighted avg       0.85      0.84      0.83       372

Best Parameters for outer loop 2: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}

Report:
              precision    recall  f1-score   support

       DSCUT       0.83      0.93      0.88        42
          EA       0.89      0.81      0.85        31
          EB       0.85      0.89      0.87        38
        GDOR       0.87      0.87      0.87        30
       Noise       0.92      0.90      0.91        91
      OTHPER       0.98      0.96      0.97       112
        RRab       0.96      0.96      0.96        28

    accuracy                           0.92       372
   macro avg       0.90      0.90      0.90       372
weighted avg       0.92      0.92      0.92       372

Best Parameters for outer loop 3: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}

Report:
              precision    recall  f1-score   support

       DSCUT       0.80      0.81      0.80        43
          EA       0.95      0.61      0.75        31
          EB       0.88      0.78      0.83        37
        GDOR       0.83      0.80      0.81        30
       Noise       0.84      0.98      0.90        91
      OTHPER       0.94      0.96      0.95       112
        RRab       1.00      0.89      0.94        28

    accuracy                           0.88       372
   macro avg       0.89      0.84      0.86       372
weighted avg       0.89      0.88      0.88       372

Best Parameters for outer loop 4: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}

Report:
              precision    recall  f1-score   support

       DSCUT       0.87      0.79      0.83        43
          EA       0.85      0.71      0.77        31
          EB       0.93      0.97      0.95        38
        GDOR       0.90      0.90      0.90        31
       Noise       0.88      0.97      0.92        91
      OTHPER       0.97      0.97      0.97       111
        RRab       0.96      0.89      0.92        27

    accuracy                           0.92       372
   macro avg       0.91      0.89      0.90       372
weighted avg       0.92      0.92      0.92       372


Average Confusion Matrix over 5 runs:
[[0.783 0.066 0.043 0.019 0.066 0.019 0.005]
 [0.052 0.761 0.032 0.    0.123 0.026 0.006]
 [0.037 0.016 0.904 0.021 0.    0.016 0.005]
 [0.04  0.06  0.073 0.747 0.053 0.027 0.   ]
 [0.018 0.018 0.    0.009 0.934 0.02  0.002]
 [0.    0.007 0.009 0.002 0.014 0.968 0.   ]
 [0.    0.    0.015 0.007 0.051 0.    0.928]]

Std Dev of Confusion Matrix over 5 runs:
[[0.15  0.066 0.041 0.017 0.041 0.018 0.01 ]
 [0.048 0.09  0.02  0.    0.047 0.024 0.013]
 [0.036 0.013 0.066 0.02  0.    0.032 0.011]
 [0.025 0.09  0.1   0.141 0.034 0.033 0.   ]
 [0.016 0.03  0.    0.011 0.064 0.03  0.004]
 [0.    0.009 0.01  0.004 0.015 0.014 0.   ]
 [0.    0.    0.018 0.014 0.037 0.    0.033]]

Average Feature Importances over 5 runs:
[0.122 0.077 0.02  0.038 0.018 0.018 0.017 0.038 0.07  0.008 0.056 0.057
 0.063 0.052 0.054 0.07  0.025 0.055 0.045 0.038 0.023 0.036]

Std Dev of  Feature Importances over 5 runs:
[0.007 0.003 0.001 0.002 0.001 0.001 0.002 0.001 0.003 0.001 0.005 0.001
 0.002 0.001 0.004 0.002 0.001 0.004 0.005 0.003 0.001 0.001]

Confusion Matrix plot saved at /Users/chancehaycock/dev/machine_learning/px402/src/models/som_and_rf_gamma/confusion_matrix_1.pdf

Feature Importance plot saved at /Users/chancehaycock/dev/machine_learning/px402/src/models/som_and_rf_gamma/feature_importance_1.pdf

=================== Average Cross Validated Scores ==================


             Macro AUC Score (OVO): 0.979 +/- 0.0109

          Weighted AUC Score (OVO): 0.982 +/- 0.0091

             Macro AUC Score (OVR): 0.982 +/- 0.0095

          Weighted AUC Score (OVR): 0.985 +/- 0.0071

                    Macro F1 Score: 0.867 +/- 0.0400

                 Weighted F1 Score: 0.892 +/- 0.0333

                 Macro Fbeta Score: 0.877 +/- 0.0359

              Weighted Fbeta Score: 0.895 +/- 0.0311

                    Log Loss Score: 0.436 +/- 0.0647

             Macro Precision Score: 0.888 +/- 0.0308

          Weighted Precision Score: 0.900 +/- 0.0278

                Macro Recall Score: 0.861 +/- 0.0399

             Weighted Recall Score: 0.894 +/- 0.0316

              Model Accuracy Score: 0.894 +/- 0.0316




Now using cross validation to find optimal hyper-parameters for the whole dataset.

Best parameters for whole data set: {'max_features': 4, 'min_samples_split': 3, 'n_estimators': 300}


Model Evaluation Complete.
