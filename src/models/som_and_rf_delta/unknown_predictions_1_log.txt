================================================================================
                               SOM and Random Forest Model                        
================================================================================

Using training file: /Users/chancehaycock/dev/machine_learning/px402/src/models/som_and_rf_delta/train.csv
Dropping DJA Class column and using 'class' instead
       epic_number   Period_1  ...  template_dist   class
0        201488365   6.734215  ...       0.846620      EA
1        201893576   0.929943  ...       0.292683      EA
2        201828402  19.278542  ...       0.627429   Noise
3        201738572  13.017493  ...       0.187259  OTHPER
4        201387169  18.393849  ...       1.040303   Noise
...            ...        ...  ...            ...     ...
20140    211074799   0.282114  ...       0.619107   Noise
20141    210688611   6.139027  ...       0.169998  OTHPER
20142    211161378  17.395973  ...       1.726620   Noise
20143    210494481  11.688837  ...       0.134297  OTHPER
20144    210690749  18.185219  ...       2.345101  OTHPER

[20145 rows x 25 columns]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=0).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
983     206080118   8.090728  13.684117  ...        16.278821       1.257157  OTHPER
1366    210637769   9.707258   9.205634  ...        10.816654       0.549326   Noise
1214    211103431  15.541120   0.311734  ...        19.104973       1.428386   Noise
661     210642322   2.170778   0.433891  ...        18.357560       0.522731      EA
41      201921381   0.560186   0.186730  ...        27.586228       0.114336      EB
...           ...        ...        ...  ...              ...            ...     ...
934     210642998   4.812327   5.323656  ...        19.646883       0.637388  OTHPER
75      204780832   0.463895   0.521200  ...        20.124612       0.659427    RRab
911     211090115   9.153080   9.648838  ...        11.661904       0.374568  OTHPER
1168    210692012  16.168000  15.391923  ...        15.033296       1.593865  OTHPER
499     210948492   0.249379   0.043493  ...        18.027756       0.095508    GDOR

[1697 rows x 25 columns]
Predictions:
[[0.006      0.         0.         ... 0.37248571 0.62151429 0.        ]
 [0.002      0.         0.         ... 0.82974408 0.16012096 0.        ]
 [0.00150602 0.         0.         ... 0.46971717 0.52473197 0.        ]
 ...
 [0.         0.         0.         ... 0.55654286 0.44246113 0.        ]
 [0.         0.         0.00122249 ... 0.56361905 0.42683266 0.        ]
 [0.         0.09509232 0.00394029 ... 0.75815232 0.14281508 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=1).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
619     210945762   0.051345   0.048729  ...         7.615773       0.356426   DSCUT
742     210383030  15.245563  16.168000  ...        11.401754       0.589893  OTHPER
1150    206420636  19.278542  18.185219  ...        15.033296       0.842343  OTHPER
521     210697335   0.054681   0.048429  ...         2.000000       0.069375   DSCUT
1108    206135591  15.693238  20.000000  ...        11.180340       0.522759  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
1581    205893603  14.294117  15.101961  ...        10.630146       1.432804   Noise
17      201517854   0.279682   0.993268  ...        22.803509       0.519830      EB
89      202963882   0.630827   1.101042  ...        24.207437       0.676034      EB
14      201238932   0.057044   0.075709  ...         1.000000       0.062095   DSCUT
317     205954517   1.263270   0.767068  ...         1.000000       0.061880    GDOR

[1697 rows x 25 columns]
Predictions:
[[0.01028529 0.002      0.         ... 0.51470906 0.47007841 0.        ]
 [0.00587688 0.         0.         ... 0.92557312 0.05855    0.        ]
 [0.00534048 0.         0.002      ... 0.39110476 0.59995731 0.        ]
 ...
 [0.         0.         0.         ... 0.75133333 0.24866667 0.        ]
 [0.004      0.0011274  0.00102354 ... 0.82511429 0.16873478 0.        ]
 [0.         0.170798   0.00971028 ... 0.71866487 0.10082685 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=2).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1438    210457936  17.781843  16.847578  ...        13.453624       2.956493   Noise
185     205546169   4.068434   2.223206  ...        18.357560       0.591412      EA
364     211050460   0.776730   0.308970  ...         8.944272       0.629425    GDOR
373     211114628   0.074759   0.126272  ...         8.062258       0.414303   DSCUT
1573    206471814  17.209250  18.185219  ...         8.485281       0.764449   Noise
...           ...        ...        ...  ...              ...            ...     ...
597     210650657   0.449030  11.861794  ...        23.853721       0.171867      EB
818     210758754   7.930646   7.521399  ...        12.727922       0.585359  OTHPER
1452    205942838  16.847578  16.006586  ...        16.401219       0.969730   Noise
671     210654881   4.057290   0.868919  ...        17.492856       0.731253      EA
1575    210429258  18.607322  17.586791  ...        17.029386       1.189476   Noise

[1697 rows x 25 columns]
Predictions:
[[1.50602410e-03 0.00000000e+00 0.00000000e+00 ... 3.54477778e-01
  6.42016198e-01 0.00000000e+00]
 [3.50602410e-03 0.00000000e+00 0.00000000e+00 ... 7.88593976e-01
  2.00761048e-01 0.00000000e+00]
 [2.00000000e-03 0.00000000e+00 1.22249389e-03 ... 4.08500000e-01
  5.82432488e-01 0.00000000e+00]
 ...
 [2.00000000e-03 0.00000000e+00 0.00000000e+00 ... 6.07595238e-01
  3.90404762e-01 0.00000000e+00]
 [0.00000000e+00 9.84251969e-04 0.00000000e+00 ... 6.58874478e-01
  3.40141270e-01 0.00000000e+00]
 [2.00000000e-03 1.40301604e-01 4.25742574e-04 ... 6.06969680e-01
  2.50302973e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=3).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
750     210506847  11.950206  11.357627  ...        12.649111       2.258133  OTHPER
400     210657179   1.104518   0.061297  ...        21.954498       0.394473      EB
1418    211051536  18.185219  19.278542  ...        12.529964       0.523476   Noise
139     202843085  16.600307   1.834092  ...        18.357560       1.673256      EA
494     210954859   0.428623   0.142856  ...        24.083189       0.504746      EB
...           ...        ...        ...  ...              ...            ...     ...
699     211179764  16.006586  15.101961  ...         4.123106       0.146092  OTHPER
1040    210758732   6.333020   6.675823  ...        11.180340       0.096875  OTHPER
161     205388726   0.066378   0.051622  ...        17.117243       0.450748   DSCUT
1396    206149878  20.000000  18.825808  ...        11.661904       0.851948   Noise
931     206139203  20.000000  18.825808  ...        11.661904       1.198795  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00320773 0.         0.         ... 0.27089964 0.72475368 0.        ]
 [0.004      0.00316088 0.         ... 0.84114637 0.14969275 0.        ]
 [0.002      0.         0.002      ... 0.49267347 0.49584762 0.        ]
 ...
 [0.00086505 0.002      0.         ... 0.81646667 0.18066828 0.        ]
 [0.00241546 0.00158983 0.         ... 0.74440245 0.25159227 0.        ]
 [0.         0.28262567 0.002      ... 0.41675225 0.29862208 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=4).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
95      204181806   0.059675   0.052811  ...         8.246211       0.553873   DSCUT
837     210817078   0.662201   0.711892  ...        16.124515       0.150945  OTHPER
1487    210427803  11.861794  12.509651  ...        12.041595       1.985729   Noise
2       201927024   0.237294   0.262613  ...        22.627417       0.182433      EB
1225    210419687  13.684117  11.277736  ...        15.033296       1.556192   Noise
...           ...        ...        ...  ...              ...            ...     ...
1042    210499961  13.801916  18.825808  ...        18.027756       2.485635  OTHPER
1109    206403369  14.167804  20.000000  ...        10.816654       0.998394  OTHPER
1206    211072855  20.000000  18.825808  ...        10.198039       1.323360   Noise
190     202911789   0.046621   0.055689  ...         6.000000       0.156846   DSCUT
1650    210407864  20.000000  18.825808  ...        13.000000       0.770721   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.00158983 0.         ... 0.41163333 0.58477684 0.        ]
 [0.002      0.         0.         ... 0.67977778 0.31489243 0.        ]
 [0.         0.         0.         ... 0.51173669 0.48111667 0.        ]
 ...
 [0.         0.         0.         ... 0.73423333 0.26576667 0.        ]
 [0.00134048 0.0011274  0.         ... 0.6467492  0.35078292 0.        ]
 [0.00180288 0.11329773 0.00473994 ... 0.69862598 0.18153346 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=5).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1258    206116906  20.000000  18.825808  ...        21.095023       0.299584   Noise
1512    210425621   8.948730  16.672383  ...        14.000000       1.627973   Noise
459     210844626   0.047563   0.449334  ...        13.601471       1.422187   DSCUT
607     210978380   0.458982   0.436252  ...         5.385165       0.068840    GDOR
1242    206300557   9.153080  17.209250  ...        11.180340       0.711375   Noise
...           ...        ...        ...  ...              ...            ...     ...
560     210311535   0.561347   0.408988  ...        18.601075       0.643092    RRab
1421    201833284  20.000000  18.825808  ...        17.262677       2.108366   Noise
749     210776828  13.124049  16.847578  ...        15.264338       0.886131  OTHPER
1642    210716968  15.848364  16.847578  ...        12.369317       1.367122   Noise
875     210996038  16.847578  16.006586  ...        14.317821       0.535707  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00550602 0.         0.         ... 0.37247017 0.61802381 0.        ]
 [0.002      0.002      0.         ... 0.82223333 0.17376667 0.        ]
 [0.         0.         0.         ... 0.48012563 0.51503333 0.        ]
 ...
 [0.002      0.         0.         ... 0.61413333 0.38386667 0.        ]
 [0.002      0.0011274  0.         ... 0.73514879 0.26083885 0.        ]
 [0.         0.1133302  0.00551745 ... 0.46706234 0.41409001 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=6).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
759     206108895   1.765427   5.763841  ...         8.602325       0.209192  OTHPER
1072    206037789  20.000000  18.825808  ...        17.000000       0.157805  OTHPER
1336    210986061  11.604237  12.223531  ...        12.649111       2.056299   Noise
648     210412360   0.105507   1.407433  ...         9.219544       0.525792    GDOR
775     210997946   4.930724  20.000000  ...         7.071068       0.248342  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
573     210796097   0.684123   0.107387  ...        23.430749       0.167783      EB
1568    211088423  15.541120  14.686938  ...        10.295630       0.476620   Noise
1603    210813978  17.026494  16.168000  ...        10.198039       0.658266   Noise
957     206068177   6.760268   7.120552  ...        15.524175       0.113734  OTHPER
542     211115338   0.052357   0.046109  ...         1.000000       0.067315   DSCUT

[1697 rows x 25 columns]
Predictions:
[[0.00350602 0.004      0.         ... 0.47390256 0.51139653 0.        ]
 [0.         0.         0.         ... 0.85801105 0.13685    0.        ]
 [0.00171821 0.         0.         ... 0.50104845 0.49723333 0.        ]
 ...
 [0.00150602 0.         0.         ... 0.64818921 0.35030476 0.        ]
 [0.00322424 0.         0.         ... 0.60692814 0.38784762 0.        ]
 [0.         0.11439882 0.00641328 ... 0.71667707 0.16251083 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=7).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist  class
1375    210939238   7.216704  10.894570  ...        10.198039       0.702483  Noise
1631    210470427  17.026494  16.168000  ...        10.440307       0.513396  Noise
48      201680569   0.784745   0.065395  ...        22.203603       0.962458     EB
682     211031397   0.056990   0.649591  ...         6.000000       0.039375  DSCUT
600     210725210   0.069089   0.044797  ...        15.652476       0.380988  DSCUT
...           ...        ...        ...  ...              ...            ...    ...
202     205945953   0.942517   0.314177  ...        22.671568       0.537441     EB
78      203692906   0.701612   0.104407  ...        21.470911       0.042183   RRab
543     211112686   0.764143  17.395973  ...         9.000000       0.217689     EB
37      201184068   1.588081   0.132382  ...        19.723083       0.372226     EA
1328    210618281  13.232365  12.509651  ...        13.000000       1.751612  Noise

[1697 rows x 25 columns]
Predictions:
[[0.00475758 0.         0.         ... 0.4465     0.54741264 0.        ]
 [0.00282125 0.00104407 0.         ... 0.90766326 0.08087398 0.        ]
 [0.         0.         0.00122249 ... 0.49577717 0.49458619 0.        ]
 ...
 [0.         0.         0.         ... 0.62671429 0.37328571 0.        ]
 [0.00150602 0.00158983 0.         ... 0.64400889 0.35089526 0.        ]
 [0.         0.06025029 0.         ... 0.48546635 0.45428335 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=8).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1488    206069049  20.000000   8.849939  ...        14.866069       2.542595   Noise
370     210894583   0.472230   0.370177  ...        18.973666       0.502190      EB
820     210575130   3.082289   8.009887  ...         2.236068       0.129440  OTHPER
1468    211071062  20.000000  18.825808  ...        13.038405       4.492962   Noise
1469    206390773  19.278542  18.185219  ...        16.124515       0.783855   Noise
...           ...        ...        ...  ...              ...            ...     ...
337     205934569   0.542924   0.180956  ...        24.758837       0.406516      EB
313     206300006   0.509119   0.084852  ...        21.540659       0.200681    RRab
1384    206065063   8.050105  17.026494  ...         9.433981       1.564114   Noise
889     206049503  19.049485  17.981269  ...         8.062258       0.179553  OTHPER
1240    210568587   6.817762   4.250922  ...        18.000000       2.537572   Noise

[1697 rows x 25 columns]
Predictions:
[[0.004      0.         0.         ... 0.27221905 0.72178095 0.        ]
 [0.00350602 0.         0.         ... 0.67341667 0.31347987 0.        ]
 [0.00431719 0.         0.00385271 ... 0.40322759 0.57579771 0.0009164 ]
 ...
 [0.002      0.         0.         ... 0.7414381  0.2565619  0.        ]
 [0.002      0.00457408 0.         ... 0.77609906 0.21732686 0.        ]
 [0.         0.17567822 0.00441328 ... 0.68348785 0.13642065 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=9).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
702     210454265  14.961038  14.167804  ...         8.062258       0.109638  OTHPER
701     206137600  18.393849  17.395973  ...        11.313708       0.908723  OTHPER
1693    205926726  20.000000  18.825808  ...        13.601471       0.750857   Noise
686     210665016   0.710001   0.760519  ...        20.615528       0.190640    RRab
871     211091536   0.821713  17.981269  ...        10.295630       0.144197  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
1063    206413297   4.945935  15.391923  ...         7.211103       0.082316  OTHPER
254     206037724   1.376125   0.458719  ...        21.400935       0.443811      EB
1596    210400786  16.672383  17.586791  ...        14.560220       1.368727   Noise
351     206074814   0.699774   0.746705  ...        13.601471       0.240355    GDOR
1402    210616849  20.000000  18.825808  ...        15.297059       1.123873   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.61006922 0.38833333 0.        ]
 [0.         0.00280563 0.         ... 0.83544957 0.15814736 0.        ]
 [0.00120773 0.         0.         ... 0.56987798 0.41808181 0.002     ]
 ...
 [0.         0.         0.         ... 0.7057     0.2943     0.        ]
 [0.         0.         0.         ... 0.7268     0.2732     0.        ]
 [0.002      0.08652117 0.0074323  ... 0.52892742 0.3751191  0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=10).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
278     205992558   0.215249   0.071748  ...        22.671568       0.910151      EB
1579    210727808  18.607322   1.332568  ...        20.024984       3.338308   Noise
1247    206023751  16.672383  17.586791  ...        10.000000       0.897273   Noise
992     206267073   1.917443   2.106375  ...        17.720045       0.217803  OTHPER
158     202554180   0.083863   0.077200  ...         4.242641       0.235564   DSCUT
...           ...        ...        ...  ...              ...            ...     ...
1304    206159978  10.969106  11.604237  ...        11.313708       1.135737   Noise
1177    206119639  20.000000  18.825808  ...        11.704700       1.228503  OTHPER
1212    210505393  20.000000  15.391923  ...        17.720045       1.664147   Noise
1241    206031298  16.672383  15.848364  ...        12.369317       1.212854   Noise
1582    206434462  16.672383  17.586791  ...        14.035669       3.674897   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.45876936 0.5327619  0.        ]
 [0.         0.         0.         ... 0.86651667 0.13059838 0.        ]
 [0.         0.         0.         ... 0.45494285 0.54195117 0.        ]
 ...
 [0.         0.         0.         ... 0.69626667 0.30373333 0.        ]
 [0.         0.         0.         ... 0.70546667 0.29320355 0.        ]
 [0.         0.20430171 0.00600664 ... 0.52390946 0.26578219 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=11).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
998     206141160  20.000000  14.961038  ...        16.124515       0.824591  OTHPER
1577    211084537  17.026494  17.981269  ...        10.630146       0.762700   Noise
1562    210401986  18.185219  19.278542  ...        13.601471       1.446812   Noise
1084    211041001  11.438657  12.131044  ...        13.000000       2.327131  OTHPER
1368    210581470  16.847578  16.006586  ...         7.615773       0.269863   Noise
...           ...        ...        ...  ...              ...            ...     ...
405     210986506   0.064630  12.707958  ...        10.049876       0.645719   DSCUT
326     206321136   1.959628   2.428633  ...         8.485281       0.911243    GDOR
1261    206024309  19.049485  17.981269  ...        12.206556       1.138741   Noise
1069    206012254  10.606287  11.198962  ...        12.041595       5.341757  OTHPER
1527    210537244  18.607322  19.753588  ...        14.317821       1.007306   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.21579908 0.77941975 0.        ]
 [0.         0.00331926 0.         ... 0.76470455 0.22797619 0.        ]
 [0.00150602 0.002      0.         ... 0.40728229 0.58536667 0.        ]
 ...
 [0.         0.         0.         ... 0.74885714 0.25114286 0.        ]
 [0.         0.         0.         ... 0.71986667 0.28013333 0.        ]
 [0.         0.20120465 0.00867068 ... 0.22263649 0.56748818 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=12).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
591     210404228   1.119948   0.093334  ...        22.203603       0.427060      EA
84      203942067   3.284893   0.273359  ...        21.095023       1.044625      EA
1032    201325244   9.312574   8.849939  ...        10.630146       0.664739  OTHPER
1205    210455333  14.822721  14.043705  ...        16.124515       1.266544   Noise
624     210378102   0.464164   0.421680  ...        14.422205       0.119546    GDOR
...           ...        ...        ...  ...              ...            ...     ...
642     210617106   0.586609  17.586791  ...        21.095023       0.108600    RRab
1421    206522450  20.000000  18.825808  ...        13.152946       1.323999   Noise
639     211020446   0.861950   0.287372  ...        22.627417       0.384600      EB
1599    210658015  13.921761  14.686938  ...        13.000000       2.093756   Noise
195     204312847  12.092840   3.461615  ...        18.357560       0.670750      EA

[1697 rows x 25 columns]
Predictions:
[[8.51408861e-03 0.00000000e+00 0.00000000e+00 ... 4.79874159e-01
  5.04819420e-01 0.00000000e+00]
 [3.71821306e-03 2.00000000e-03 0.00000000e+00 ... 8.32948454e-01
  1.59333333e-01 0.00000000e+00]
 [2.77370479e-03 0.00000000e+00 2.00000000e-03 ... 3.83579381e-01
  6.11646914e-01 0.00000000e+00]
 ...
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.43833333e-01
  3.54836879e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.43266667e-01
  3.56733333e-01 0.00000000e+00]
 [0.00000000e+00 1.65572349e-01 5.77181208e-04 ... 5.63714400e-01
  2.70136070e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=13).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
706     206354061   1.082458   8.009887  ...        10.816654       0.509569  OTHPER
391     210752606   0.060533   0.075289  ...         3.605551       0.063377   DSCUT
1236    210516523   5.682133   4.856053  ...         5.830952       0.129336   Noise
1024    206017077   9.707258   8.090728  ...        10.049876       0.789220  OTHPER
663     210958990   1.701866   0.567305  ...        18.601075       0.223846      EA
...           ...        ...        ...  ...              ...            ...     ...
1028    211111496   7.152317   7.556850  ...        16.000000       0.099020  OTHPER
83      202844711   6.176452   0.514510  ...        19.723083       0.660690      EA
981     210407396   1.531085   0.636693  ...        11.313708       1.267252  OTHPER
1558    205962913  14.043705  10.748495  ...        15.132746       1.968624   Noise
1200    211109320  12.412801  13.124049  ...        15.033296       1.613872   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.2772     0.7228     0.        ]
 [0.00337914 0.00131926 0.         ... 0.73697896 0.25044117 0.        ]
 [0.         0.         0.         ... 0.46676922 0.52963333 0.        ]
 ...
 [0.002      0.         0.         ... 0.7369     0.2571     0.        ]
 [0.         0.00177148 0.         ... 0.74946838 0.2471627  0.        ]
 [0.         0.31655452 0.0093541  ... 0.48076716 0.19332422 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=14).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
135     204558724   0.635830   0.211904  ...        25.495098       0.149354      EB
1367    211144496  14.294117  20.000000  ...        15.620499       1.409573   Noise
897     210608122  10.073190  10.606287  ...         6.324555       0.115725  OTHPER
933     211068258  18.607322  19.753588  ...        18.384776       0.548818  OTHPER
97      205060983   0.329688   0.479432  ...        25.612497       0.166450      EB
...           ...        ...        ...  ...              ...            ...     ...
1096    206279654   3.339058   3.130434  ...        11.401754       0.212722  OTHPER
1386    210431663  20.000000  18.825808  ...         8.602325       0.790227   Noise
1143    211064647   9.591118   1.337013  ...        17.464249       1.123125  OTHPER
1137    206035381  13.454450  14.167804  ...        12.041595       0.856993  OTHPER
233     205994924   0.051923   0.070157  ...         4.123106       0.072259   DSCUT

[1697 rows x 25 columns]
Predictions:
[[0.00184843 0.         0.         ... 0.28013589 0.71241824 0.        ]
 [0.         0.         0.         ... 0.83337065 0.16563333 0.        ]
 [0.         0.00170648 0.         ... 0.49830952 0.49998399 0.        ]
 ...
 [0.         0.         0.         ... 0.69398571 0.30601429 0.        ]
 [0.         0.         0.         ... 0.7375     0.2625     0.        ]
 [0.         0.16060171 0.00572563 ... 0.56817164 0.26550103 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=15).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
950     206270259  13.801916  13.124049  ...        10.630146       1.631776  OTHPER
976     205962080  18.393849  19.513174  ...         7.000000       0.091415  OTHPER
1105    206115519   7.930646  14.686938  ...        18.973666       0.312189  OTHPER
902     206075431  15.541120  16.500795  ...        15.000000       0.807423  OTHPER
1021    211046446   7.852958   8.300153  ...        11.313708       1.356219  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
101     205062129   0.513042   0.171052  ...        26.172505       0.118186      EB
1674    206018872  16.847578  16.006586  ...        12.369317       1.197250   Noise
549     210936757   2.223206   2.343439  ...        19.000000       0.213666    GDOR
1139    210432248  14.822721  20.000000  ...        13.038405       2.050972  OTHPER
222     205988562   0.548308   0.182771  ...        22.671568       0.459686      EB

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.48807142 0.49855494 0.        ]
 [0.0057311  0.00158983 0.         ... 0.62249614 0.35997185 0.        ]
 [0.         0.         0.00372563 ... 0.38683511 0.59634392 0.        ]
 ...
 [0.         0.         0.         ... 0.72106667 0.27893333 0.        ]
 [0.00150602 0.         0.         ... 0.59641905 0.40207493 0.        ]
 [0.         0.14505833 0.00977461 ... 0.68055676 0.16461031 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=16).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1658    206031887  18.607322  19.753588  ...        17.088007       1.782227   Noise
738     205928894  14.686938  13.921761  ...        13.152946       0.076828  OTHPER
934     210623841   2.210943   2.103611  ...        14.422205       0.416756  OTHPER
951     210404097  17.209250  13.232365  ...         9.055385       0.446811  OTHPER
413     210729707   0.638468   0.106431  ...        20.591260       0.041345    RRab
...           ...        ...        ...  ...              ...            ...     ...
229     206149993   0.537990   0.089659  ...        21.540659       0.853220    RRab
334     206017313   0.271719   0.304684  ...        26.248809       0.175571      EB
1038    206143580   4.501562   3.609692  ...        10.440307       1.461101  OTHPER
1522    210990151  18.607322  17.586791  ...        12.165525       1.181749   Noise
1063    210423467   3.617837   3.360051  ...        17.804494       1.373595  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00150602 0.         0.         ... 0.43817731 0.55631667 0.        ]
 [0.         0.         0.         ... 0.82038571 0.17761429 0.        ]
 [0.00171821 0.         0.         ... 0.48670355 0.50824845 0.        ]
 ...
 [0.002      0.         0.         ... 0.6427     0.3553     0.        ]
 [0.006      0.         0.         ... 0.85458333 0.13941667 0.        ]
 [0.         0.20688449 0.00644499 ... 0.43822499 0.34844554 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=17).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1676    206532888  20.000000  18.825808  ...        10.630146       0.707304   Noise
960     211030231   1.159991   1.241746  ...        15.620499       0.742099  OTHPER
1207    206222171  18.607322  17.586791  ...        12.041595       1.190649   Noise
1409    210853461  17.395973  18.393849  ...        14.866069       2.109561   Noise
721     210716610  18.825808  17.781843  ...        11.180340       0.687121  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
1615    210346054  20.000000  15.101961  ...        12.369317       1.922343   Noise
1085    206300127  12.412801  13.124049  ...         4.123106       0.121393  OTHPER
490     210507674   0.483188   0.525643  ...         8.062258       0.227454    GDOR
532     210929566   0.055179   0.513357  ...         9.219544       0.608690    GDOR
1098    206335582  12.707958  12.039946  ...        15.000000       1.278839  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00433638 0.002      0.         ... 0.44369559 0.54996803 0.        ]
 [0.         0.002      0.         ... 0.88208333 0.10991667 0.        ]
 [0.002      0.002      0.         ... 0.47446681 0.51354844 0.        ]
 ...
 [0.00120773 0.         0.         ... 0.60708751 0.39170476 0.        ]
 [0.00120773 0.00177148 0.         ... 0.66043984 0.33658095 0.        ]
 [0.         0.09035031 0.002      ... 0.76153064 0.14611905 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=18).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1018    206360900   6.834691   7.216704  ...        16.401219       2.135375  OTHPER
52      201671506   1.413638   1.488443  ...        16.124515       0.057215    GDOR
1398    210680009  15.391923  12.131044  ...        13.000000       1.502088   Noise
1515    210594805  19.049485  17.981269  ...        10.816654       1.980427   Noise
674     210380478   0.383825   0.466324  ...         5.000000       0.413383    GDOR
...           ...        ...        ...  ...              ...            ...     ...
499     210948492   0.249379   0.043493  ...        18.027756       0.095508    GDOR
1570    205992463  20.000000  18.825808  ...        15.620499       1.369397   Noise
1176    210342593  17.981269  14.822721  ...        15.231546       1.409600  OTHPER
959     211110509   3.402839   5.622355  ...        14.866069       0.534216  OTHPER
1634    206182342  18.825808  20.000000  ...        14.212670       1.552483   Noise

[1697 rows x 25 columns]
Predictions:
[[0.00184843 0.         0.         ... 0.34893333 0.64921824 0.        ]
 [0.00649306 0.00140128 0.002866   ... 0.68706709 0.29691964 0.        ]
 [0.         0.         0.         ... 0.49173589 0.50666667 0.        ]
 ...
 [0.         0.00098425 0.         ... 0.57006667 0.42894908 0.        ]
 [0.         0.00158983 0.         ... 0.6812381  0.31517208 0.        ]
 [0.         0.10359892 0.00165017 ... 0.67079028 0.22396063 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=19).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
89      202963882   0.630827   1.101042  ...        24.207437       0.676034      EB
1152    211026276   0.537089   0.451358  ...        16.155494       0.262832  OTHPER
1128    210837492   5.306038   5.039206  ...        10.630146       0.602620  OTHPER
120     204574155   0.062975   0.059304  ...         5.000000       0.098426   DSCUT
69      202643279   2.343721   0.468641  ...        21.931712       0.097032      EB
...           ...        ...        ...  ...              ...            ...     ...
470     210742688   1.267264   5.662066  ...        17.804494       0.457681      EA
804     210418928  11.861794  12.509651  ...         7.615773       0.416764  OTHPER
1235    210521832  16.500795  15.693238  ...         9.433981       1.547441   Noise
969     211040706  18.185219  17.209250  ...        14.317821       0.557624  OTHPER
642     210617106   0.586609  17.586791  ...        21.095023       0.108600    RRab

[1697 rows x 25 columns]
Predictions:
[[0.00086505 0.         0.         ... 0.38848095 0.610654   0.        ]
 [0.00150602 0.         0.         ... 0.75706667 0.23443129 0.        ]
 [0.         0.         0.00151745 ... 0.44435494 0.54893272 0.        ]
 ...
 [0.004      0.         0.         ... 0.6634     0.3306     0.        ]
 [0.         0.002      0.         ... 0.74033333 0.25366667 0.        ]
 [0.         0.11487393 0.01206152 ... 0.66514712 0.20791742 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=20).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1239    206405208  20.000000  18.825808  ...        10.049876       0.597478   Noise
255     205941274   0.550930   0.091816  ...        21.540659       0.306720    RRab
1421    206234359  13.921761  20.000000  ...        11.401754       1.098559   Noise
937     206200994  20.000000  18.825808  ...        14.142136       0.322609  OTHPER
656     210796886   0.079913   0.091210  ...         1.000000       0.048651   DSCUT
...           ...        ...        ...  ...              ...            ...     ...
1096    210878635   0.474747   9.648838  ...         3.000000       0.183181  OTHPER
1427    205917896  20.000000  18.825808  ...        10.049876       1.057698   Noise
388     210607917   0.559779   0.436015  ...        19.849433       0.279532    RRab
1172    210832295   3.454157   3.277624  ...        10.630146       0.604769  OTHPER
1146    210561013  13.454450   7.089068  ...        17.029386       3.242143  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.47426667 0.52213589 0.        ]
 [0.00938312 0.         0.00311735 ... 0.88235879 0.1008383  0.        ]
 [0.00122275 0.00209651 0.002      ... 0.58034286 0.41433788 0.        ]
 ...
 [0.         0.         0.         ... 0.79353333 0.20646667 0.        ]
 [0.00150602 0.         0.002      ... 0.73326667 0.26322731 0.        ]
 [0.         0.15712939 0.00224604 ... 0.5676156  0.27300898 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=21).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1643    210646889  17.395973  16.500795  ...        15.033296       2.378088   Noise
705     206073513  13.568312  18.607322  ...         8.000000       0.770432  OTHPER
377     210822691   8.073717   0.672760  ...        19.235384       0.853103      EA
490     210507674   0.483188   0.525643  ...         8.062258       0.227454    GDOR
1054    201789080  11.774681  11.198962  ...        14.866069       0.322241  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
954     211176536   2.106375  10.676918  ...         7.071068       1.283338  OTHPER
1199    206380190  20.000000  18.825808  ...        12.041595       0.500526   Noise
1204    211129795  12.509651  11.861794  ...        16.031220       2.391061   Noise
300     206146130   0.156112  20.000000  ...        16.000000       0.147201   DSCUT
1570    206102047  17.781843  11.198962  ...        12.806248       2.458109   Noise

[1697 rows x 25 columns]
Predictions:
[[0.00120773 0.         0.         ... 0.4409     0.55285015 0.        ]
 [0.002      0.         0.         ... 0.77783333 0.21616667 0.        ]
 [0.         0.         0.         ... 0.52686667 0.46913333 0.        ]
 ...
 [0.         0.         0.         ... 0.79478571 0.20521429 0.        ]
 [0.         0.         0.         ... 0.69928287 0.29726575 0.        ]
 [0.         0.16013098 0.00669102 ... 0.55413923 0.27903876 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=22).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1009    211092628   0.632673   0.400308  ...         2.828427       0.289566  OTHPER
39      201810513   1.645958   0.137220  ...        20.124612       0.536111      EA
405     210986506   0.064630  12.707958  ...        10.049876       0.645719   DSCUT
61      201716883   0.555704   0.585966  ...        21.023796       0.051719    RRab
902     210764483  11.688837  12.317439  ...        16.278821       0.252707  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
430     210875952   0.153717   0.412142  ...         9.899495       1.792695   DSCUT
537     211015722   2.182598   0.728056  ...        18.357560       0.205899      EA
1341    206087247  19.513174  18.393849  ...        10.440307       0.967467   Noise
604     210615776   0.723130   2.134416  ...        10.630146       0.349148    GDOR
580     210471429   0.516167   0.086045  ...        21.540659       0.323435    RRab

[1697 rows x 25 columns]
Predictions:
[[4.02011271e-03 0.00000000e+00 0.00000000e+00 ... 5.27424621e-01
  4.68555266e-01 0.00000000e+00]
 [4.76345214e-04 1.21117233e-03 7.75222415e-04 ... 8.56133333e-01
  1.40425670e-01 0.00000000e+00]
 [0.00000000e+00 2.00000000e-03 0.00000000e+00 ... 4.41314286e-01
  5.47689698e-01 0.00000000e+00]
 ...
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.50666667e-01
  2.49333333e-01 0.00000000e+00]
 [3.71821306e-03 8.73362445e-04 0.00000000e+00 ... 7.75048414e-01
  2.18478543e-01 0.00000000e+00]
 [0.00000000e+00 2.17562560e-01 6.54099214e-03 ... 3.90282070e-01
  3.85614379e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=23).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
217     205926273   0.094863   3.762155  ...         3.000000       0.047464   DSCUT
1121    206026656  12.809487  13.568312  ...         7.810250       0.331706  OTHPER
111     205114328   0.600449   0.414593  ...        20.124612       0.576819    RRab
380     210598340   3.732225   1.245605  ...        19.849433       0.354013      EA
930     206157908   0.260058   3.461615  ...         9.219544       1.101049  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
617     210835735   0.429829   0.143277  ...        26.248809       0.393385      EB
1638    206059464  16.332702  17.209250  ...        13.892444       1.168324   Noise
973     210907473   1.390346   1.306506  ...        13.038405       0.156050  OTHPER
576     210740200   3.396226   1.131342  ...        18.357560       0.421389      EA
44      201379113  11.688837   7.120552  ...        16.552945       0.909715      EA

[1697 rows x 25 columns]
Predictions:
[[0.         0.002      0.         ... 0.40989683 0.58610317 0.        ]
 [0.         0.00184162 0.         ... 0.91716314 0.07699524 0.        ]
 [0.         0.         0.         ... 0.47006667 0.52746459 0.        ]
 ...
 [0.         0.         0.         ... 0.63870952 0.36129048 0.        ]
 [0.         0.         0.         ... 0.7924381  0.2075619  0.        ]
 [0.         0.10370501 0.00548849 ... 0.76236513 0.12844137 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=24).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
438     210450012   0.185327  17.026494  ...         9.433981       0.442480   DSCUT
925     210419966  11.604237   9.422027  ...        14.866069       2.054193  OTHPER
952     206096303  13.342483  12.608025  ...        16.000000       1.489204  OTHPER
1045    210378120   9.948185  12.809487  ...        12.041595       0.200496  OTHPER
136     202929357   0.092366   0.109119  ...         6.324555       0.343952   DSCUT
...           ...        ...        ...  ...              ...            ...     ...
415     210542037   6.188372   6.539673  ...        21.633308       0.839943      EB
340     206058387   0.375472   0.125158  ...        24.207437       0.178083      EB
934     210716981  18.607322  19.753588  ...        15.033296       2.354333  OTHPER
945     206340739   8.475665  17.981269  ...         9.000000       0.517106  OTHPER
1677    210671374  16.006586  20.000000  ...        17.000000       0.545848   Noise

[1697 rows x 25 columns]
Predictions:
[[0.004      0.         0.         ... 0.42391429 0.56875593 0.        ]
 [0.002      0.00177148 0.         ... 0.82633719 0.16675238 0.        ]
 [0.00171821 0.         0.00180832 ... 0.5755068  0.41741427 0.        ]
 ...
 [0.         0.         0.         ... 0.63713333 0.36286667 0.        ]
 [0.00350602 0.002      0.         ... 0.66908921 0.32540476 0.        ]
 [0.         0.14751438 0.01082552 ... 0.55916655 0.28064853 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=25).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
472     210373111   0.162012   0.477575  ...         9.055385       0.103890   DSCUT
135     204558724   0.635830   0.211904  ...        25.495098       0.149354      EB
655     210453345   0.493614   0.164556  ...        25.455844       0.114886      EB
1585    210547171  14.961038  15.848364  ...        10.049876       0.224830   Noise
118     203868608   4.547301   5.583198  ...        18.357560       0.742802      EA
...           ...        ...        ...  ...              ...            ...     ...
216     206126731   0.560758   0.170597  ...        21.540659       0.111088    RRab
436     211096084   0.575984   0.085985  ...        26.248809       0.310626      EB
1253    210460953  20.000000  18.825808  ...        17.464249       0.773292   Noise
1448    210451747  16.847578  16.006586  ...         9.219544       0.502602   Noise
786     206161641  17.395973  16.500795  ...         7.280110       0.296876  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00300806 0.         0.         ... 0.48222051 0.51077143 0.        ]
 [0.00288055 0.00224685 0.         ... 0.68752754 0.28660867 0.        ]
 [0.         0.         0.00082271 ... 0.41197566 0.58200675 0.        ]
 ...
 [0.00088055 0.00111945 0.         ... 0.60816667 0.38783333 0.        ]
 [0.00150602 0.00177148 0.         ... 0.578719   0.4180035  0.        ]
 [0.         0.0828034  0.         ... 0.81569521 0.1015014  0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=26).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
805     211119703  15.693238  14.822721  ...         8.062258       0.677855  OTHPER
346     206314169   0.585324   0.536729  ...         5.000000       0.126937    GDOR
1437    210663518  20.000000  11.277736  ...        19.104973       1.919409   Noise
1112    211018702   7.089068   7.486280  ...        10.000000       0.466602  OTHPER
638     210748304   0.717949   0.894117  ...         9.219544       0.377223    GDOR
...           ...        ...        ...  ...              ...            ...     ...
281     206288771   0.638722   0.397135  ...        20.591260       0.098039    RRab
1017    210641434  12.707958  13.454450  ...        18.000000       0.146812  OTHPER
868     210940401  20.000000  11.861794  ...         9.055385       0.458682  OTHPER
648     210412360   0.105507   1.407433  ...         9.219544       0.525792    GDOR
784     206373693  14.822721  15.693238  ...        13.038405       1.085648  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00171821 0.         0.         ... 0.31630737 0.67291535 0.        ]
 [0.         0.         0.         ... 0.9457     0.05270256 0.        ]
 [0.         0.         0.         ... 0.482      0.518      0.        ]
 ...
 [0.         0.         0.         ... 0.78353333 0.21646667 0.        ]
 [0.002      0.         0.         ... 0.76649048 0.23150952 0.        ]
 [0.         0.13148465 0.00545421 ... 0.65433867 0.20872248 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=27).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
286     205955110   0.594659   0.173552  ...        20.124612       0.051031    RRab
1529    206455216  14.961038  14.167804  ...        15.000000       1.475911   Noise
824     206080993   1.821589   1.950094  ...        20.000000       0.820601  OTHPER
950     206043475   3.899405   4.228499  ...        17.888544       0.891620  OTHPER
206     206212261  15.478475   5.169181  ...        18.357560       0.803740      EA
...           ...        ...        ...  ...              ...            ...     ...
329     206175324   0.740155   0.123377  ...        13.892444       3.150951    RRab
1641    206371423  11.520852  10.969106  ...         9.055385       0.658355   Noise
579     210794599   0.102400   0.090184  ...         5.000000       0.101077   DSCUT
1668    211000308   2.957216  17.395973  ...        10.295630       1.142792   Noise
768     210976649  20.000000  18.825808  ...        13.152946       1.873828  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00364114 0.         0.         ... 0.4457381  0.54973581 0.        ]
 [0.00275758 0.004      0.         ... 0.89721485 0.09257619 0.        ]
 [0.         0.00177148 0.         ... 0.67953333 0.31691899 0.        ]
 ...
 [0.002      0.         0.         ... 0.56484286 0.43315714 0.        ]
 [0.002      0.         0.         ... 0.59342857 0.40124164 0.        ]
 [0.         0.24501132 0.0099772  ... 0.54985181 0.19515968 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=28).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1596    210781150  18.393849  19.513174  ...         8.062258       0.201974   Noise
629     210793743   1.136152   0.189332  ...        17.492856       0.273471      EA
1062    210557561  17.981269  17.026494  ...        17.029386       1.557783  OTHPER
482     210480960   1.220942   1.117932  ...         8.062258       0.081417    GDOR
73      203463506   0.695851   0.231953  ...        25.495098       0.196496      EB
...           ...        ...        ...  ...              ...            ...     ...
233     205994924   0.051923   0.070157  ...         4.123106       0.072259   DSCUT
918     201707257  13.801916  14.553620  ...         5.830952       0.204080  OTHPER
608     210487662   0.051701   0.048215  ...         5.830952       0.526747   DSCUT
356     206096844   0.390374   0.075300  ...        25.495098       0.281297      EB
1020    206268516  14.167804  13.454450  ...         6.708204       0.292553  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.00171821 0.         0.         ... 0.44043333 0.55784845 0.        ]
 [0.         0.         0.         ... 0.84475713 0.15146667 0.        ]
 [0.         0.00177148 0.         ... 0.46843463 0.52751598 0.        ]
 ...
 [0.002      0.         0.         ... 0.6256     0.3724     0.        ]
 [0.         0.         0.         ... 0.71504286 0.28495714 0.        ]
 [0.         0.09797186 0.00372563 ... 0.60498991 0.2933126  0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=29).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
905     210796052  11.688837  11.121280  ...        11.661904       0.448216  OTHPER
1228    211172597  20.000000  13.342483  ...        13.000000       1.513938   Noise
321     206187484   1.825909   0.608424  ...        17.492856       0.259214      EA
747     210458271   5.039206   9.477724  ...        15.132746       1.519345  OTHPER
12      201398311   0.464567   0.077431  ...        21.540659       0.689021    RRab
...           ...        ...        ...  ...              ...            ...     ...
985     206076743  14.686938  15.541120  ...         9.486833       1.044859  OTHPER
375     211070599   2.055076   3.211962  ...        16.124515       0.062632    GDOR
574     210367220   1.496896   0.499133  ...        19.104973       0.458751      EB
1469    206018634  18.825808  17.781843  ...         8.246211       0.625042   Noise
86      203596245   0.461625   0.523412  ...        21.023796       0.123951    RRab

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.50848671 0.48918749 0.        ]
 [0.002      0.         0.         ... 0.90556667 0.08843333 0.        ]
 [0.00180288 0.         0.         ... 0.49307115 0.5002067  0.        ]
 ...
 [0.         0.         0.         ... 0.58882857 0.41117143 0.        ]
 [0.         0.         0.         ... 0.75443333 0.24556667 0.        ]
 [0.         0.10487775 0.00351745 ... 0.69126609 0.20033872 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=30).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1173    205896226  16.672383  15.848364  ...        18.681542       0.176812  OTHPER
1187    211173272  20.000000  12.809487  ...        19.798990       0.892752  OTHPER
486     210794158   0.558803   0.502575  ...         9.219544       0.195885    GDOR
714     211078279   9.049751   8.612248  ...        18.788294       0.294691  OTHPER
1122    210576001  14.167804  13.454450  ...        18.027756       1.828355  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
521     210697335   0.054681   0.048429  ...         2.000000       0.069375   DSCUT
790     206058994  14.961038  15.848364  ...        12.369317       0.084419  OTHPER
1505    210960616  16.332702  15.541120  ...         5.385165       0.564202   Noise
743     206024635  20.000000  18.825808  ...        16.552945       0.240980  OTHPER
1281    211138537  13.921761  13.232365  ...        15.000000       1.313464   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.0011274  0.002      ... 0.24083333 0.75603927 0.        ]
 [0.00100806 0.00098425 0.         ... 0.86425729 0.1212579  0.        ]
 [0.004      0.00190186 0.004      ... 0.45996429 0.52213385 0.        ]
 ...
 [0.         0.         0.         ... 0.52366667 0.47633333 0.        ]
 [0.002      0.         0.         ... 0.77237143 0.22562857 0.        ]
 [0.         0.27252201 0.01049289 ... 0.47350667 0.24347843 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=31).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
901     206512790   0.850482   0.805611  ...        17.804494       1.428726  OTHPER
137     202652559   1.823661   1.477470  ...        20.000000       0.372863    GDOR
1581    206118565  11.044669   8.386991  ...        10.770330       1.670216   Noise
423     210786891   1.719973   0.286397  ...        18.384776       0.153557      EA
1388    206106578  11.044669  20.000000  ...        13.416408       1.486224   Noise
...           ...        ...        ...  ...              ...            ...     ...
925     210750096  14.043705  14.822721  ...        15.000000       1.474532  OTHPER
205     206226502   0.130698   0.137668  ...         1.000000       0.073098   DSCUT
1453    210410183  20.000000   9.101122  ...        18.248288       5.324746   Noise
1551    210742184  10.136878   4.130457  ...        16.552945       0.824394   Noise
203     206134477   4.235005   0.353059  ...        19.723083       0.912718      EA

[1697 rows x 25 columns]
Predictions:
[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.14969048e-01
  5.85030952e-01 0.00000000e+00]
 [8.68965517e-04 2.00000000e-03 0.00000000e+00 ... 8.26614286e-01
  1.64458483e-01 0.00000000e+00]
 [0.00000000e+00 9.84251969e-04 5.67567568e-04 ... 5.84796700e-01
  4.04337580e-01 0.00000000e+00]
 ...
 [0.00000000e+00 2.00000000e-03 0.00000000e+00 ... 6.73933333e-01
  3.24066667e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.00113948e-01
  2.97966667e-01 0.00000000e+00]
 [0.00000000e+00 2.10276880e-01 3.15675255e-03 ... 6.10006054e-01
  1.76560313e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=32).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist  class
1436    210606490  15.541120  14.686938  ...        14.422205       2.070782  Noise
1429    206223915  11.121280  15.391923  ...        15.033296       0.907218  Noise
1251    206208146  14.553620  19.513174  ...        12.529964       1.160040  Noise
607     210978380   0.458982   0.436252  ...         5.385165       0.068840   GDOR
1486    210414596  19.513174  18.393849  ...        11.401754       1.855657  Noise
...           ...        ...        ...  ...              ...            ...    ...
192     203878683   4.552692   4.797926  ...        15.556349       0.594261     EA
508     211129400   2.841897   2.689354  ...        15.000000       0.067902   GDOR
65      205405404   0.643357   0.214426  ...        24.758837       0.252024     EB
1395    206123112  20.000000  12.608025  ...        13.038405       1.069388  Noise
463     210596591   0.451612   0.520524  ...        12.529964       0.680779   GDOR

[1697 rows x 25 columns]
Predictions:
[[0.00380288 0.         0.         ... 0.47819712 0.51640256 0.        ]
 [0.002      0.00144196 0.         ... 0.80465524 0.18630536 0.        ]
 [0.002      0.00237475 0.002      ... 0.54705594 0.44497187 0.        ]
 ...
 [0.         0.         0.         ... 0.58183333 0.41816667 0.        ]
 [0.00320773 0.00177148 0.         ... 0.75492466 0.23809614 0.        ]
 [0.         0.08133444 0.00434908 ... 0.70586863 0.20844785 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=33).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1425    206485564  20.000000  18.825808  ...        13.152946       2.039703   Noise
1011    210379141   0.976927  15.693238  ...        11.000000       0.086247  OTHPER
842     206103608  14.961038  14.167804  ...        13.601471       0.713780  OTHPER
1680    210448454  20.000000  18.825808  ...        18.027756       0.962615   Noise
528     210903662   2.414007   0.241019  ...        14.212670       0.278453      EA
...           ...        ...        ...  ...              ...            ...     ...
835     210602466   7.891611   8.343346  ...        13.152946       0.058123  OTHPER
1256    210550896  15.391923  14.553620  ...        15.811388       1.389773   Noise
154     205275157   3.121794   1.179620  ...        22.671568       1.614847    GDOR
1587    205957213  17.026494  17.981269  ...        15.033296       0.916617   Noise
397     210472261   0.047666   0.184136  ...         4.123106       0.147667   DSCUT

[1697 rows x 25 columns]
Predictions:
[[0.002      0.         0.         ... 0.4757     0.51941504 0.        ]
 [0.         0.         0.         ... 0.70279047 0.29543333 0.        ]
 [0.002      0.         0.00151745 ... 0.45371905 0.54116606 0.        ]
 ...
 [0.002      0.         0.         ... 0.61473333 0.38326667 0.        ]
 [0.0030989  0.         0.         ... 0.75583443 0.24106667 0.        ]
 [0.         0.0993206  0.00102354 ... 0.7436794  0.15597646 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=34).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1249    210917018   4.414795   0.356276  ...        13.038405       1.949327   Noise
54      201552030   0.311587   0.103860  ...        26.172505       0.268482      EB
725     210762875   0.558025  15.693238  ...         5.099020       0.097771  OTHPER
1377    210489239  14.043705  13.342483  ...        10.630146       0.529330   Noise
1629    210733029  15.391923  20.000000  ...        16.401219       1.074436   Noise
...           ...        ...        ...  ...              ...            ...     ...
604     210615776   0.723130   2.134416  ...        10.630146       0.349148    GDOR
691     210489231   0.413906   0.137976  ...        22.203603       0.505561      EB
663     210958990   1.701866   0.567305  ...        18.601075       0.223846      EA
593     210734337   9.371496   1.040991  ...        18.357560       1.113499      EA
372     211036665   1.414364   0.377321  ...        19.723083       0.629021      EB

[1697 rows x 25 columns]
Predictions:
[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.94803984e-01
  6.02200000e-01 0.00000000e+00]
 [2.86505190e-03 1.42281879e-03 5.77181208e-04 ... 8.67116903e-01
  1.20566667e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 1.80831826e-03 ... 4.43280952e-01
  5.50910729e-01 0.00000000e+00]
 ...
 [8.65051903e-04 0.00000000e+00 0.00000000e+00 ... 6.19086522e-01
  3.80048426e-01 0.00000000e+00]
 [8.65051903e-04 0.00000000e+00 0.00000000e+00 ... 7.92091284e-01
  2.07043665e-01 0.00000000e+00]
 [0.00000000e+00 1.49502734e-01 5.61434903e-03 ... 5.92442438e-01
  2.52440479e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=35).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1302    211044286   1.089075   0.054703  ...        20.024984       1.809988   Noise
1634    206167661  11.861794  11.277736  ...        12.165525       1.832873   Noise
667     210384744   0.059965   0.056862  ...        12.649111       0.112865   DSCUT
1480    210684722  15.245563  16.168000  ...        15.297059       1.917513   Noise
1310    210784972  10.399892   9.886839  ...        13.928388       0.371618   Noise
...           ...        ...        ...  ...              ...            ...     ...
97      205060983   0.329688   0.479432  ...        25.612497       0.166450      EB
731     206069011  16.672383  17.586791  ...        11.180340       0.539695  OTHPER
1402    210744693  12.912652  12.223531  ...        18.384776       1.273661   Noise
1670    210442792  10.467792  15.541120  ...        16.000000       2.391364   Noise
869     210561322  19.753588  18.607322  ...        11.401754       1.246811  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.00102354 ... 0.25679551 0.74018095 0.        ]
 [0.00286505 0.         0.         ... 0.84883414 0.14430081 0.        ]
 [0.         0.002      0.         ... 0.5181407  0.47872035 0.        ]
 ...
 [0.         0.         0.         ... 0.77473333 0.22526667 0.        ]
 [0.002      0.         0.         ... 0.79019048 0.20780952 0.        ]
 [0.         0.19160089 0.0045996  ... 0.6274086  0.17639091 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=36).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1006    206089232   7.417015  18.607322  ...         3.605551       0.058666  OTHPER
575     210375765   0.195663   0.346048  ...         7.000000       0.075550   DSCUT
1637    206496376  20.000000   8.215096  ...        16.031220       1.128496   Noise
997     206098723  19.753588  18.607322  ...        15.524175       1.391239  OTHPER
642     210617106   0.586609  17.586791  ...        21.095023       0.108600    RRab
...           ...        ...        ...  ...              ...            ...     ...
1443    210531062  10.467792  13.568312  ...        13.152946       1.269068   Noise
323     205924614   2.852007   0.407118  ...        18.357560       0.347171      EA
426     211030057   0.557056  18.185219  ...        19.313208       0.695009      EB
241     206094715   0.587594   1.476110  ...        23.600847       0.664440      EA
538     210772819   0.046054   0.042331  ...        11.045361       0.059615   DSCUT

[1697 rows x 25 columns]
Predictions:
[[3.20772947e-03 0.00000000e+00 2.00000000e-03 ... 3.72112205e-01
  6.17350279e-01 0.00000000e+00]
 [4.07766990e-04 0.00000000e+00 0.00000000e+00 ... 8.33984849e-01
  1.59323801e-01 0.00000000e+00]
 [0.00000000e+00 2.00000000e-03 2.00000000e-03 ... 4.66066667e-01
  5.29933333e-01 0.00000000e+00]
 ...
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.91240651e-01
  3.05161905e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.86802556e-01
  3.07600000e-01 0.00000000e+00]
 [2.00000000e-03 1.90356603e-01 5.86386377e-03 ... 5.64339194e-01
  2.37440340e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=37).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
923     210779340   1.097274  20.000000  ...         8.485281       0.328578  OTHPER
111     205114328   0.600449   0.414593  ...        20.124612       0.576819    RRab
472     210373111   0.162012   0.477575  ...         9.055385       0.103890   DSCUT
792     211068830  18.185219  17.209250  ...        21.260292       1.267592  OTHPER
845     206132041  12.921234  12.223531  ...        17.029386       1.599413  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
519     210925792   0.581292   0.172432  ...        21.023796       0.063724    RRab
1298    206063183  20.000000  18.825808  ...        13.341664       1.035398   Noise
130     204091956   0.590280   0.101576  ...        20.000000       0.126394    RRab
1148    211063749  19.049485  17.981269  ...        13.038405       2.004467  OTHPER
533     211147178   5.734618   1.910588  ...        18.357560       0.215602      EA

[1697 rows x 25 columns]
Predictions:
[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.62607937e-01
  6.37392063e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 8.76578571e-01
  1.23421429e-01 0.00000000e+00]
 [1.11132170e-03 7.06421544e-04 0.00000000e+00 ... 4.49025114e-01
  5.43157143e-01 0.00000000e+00]
 ...
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.69649206e-01
  3.30350794e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.23452381e-01
  2.76547619e-01 0.00000000e+00]
 [0.00000000e+00 1.59785097e-01 2.57718121e-03 ... 5.49093486e-01
  2.88544236e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=38).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
343     206087590   0.589629   0.173158  ...        20.591260       0.077945    RRab
1091    206238495  15.245563  14.422701  ...         9.219544       1.023810  OTHPER
625     210470747   4.427993   0.369069  ...        19.235384       0.892540      EA
902     211019369   0.316534  10.332867  ...         9.219544       0.463586  OTHPER
1390    210703995  15.693238  14.822721  ...        18.000000       1.454412   Noise
...           ...        ...        ...  ...              ...            ...     ...
159     205152526   0.439843   0.170090  ...        16.401219       2.177627    RRab
228     206164678   0.209632   0.077356  ...         2.236068       0.104859   DSCUT
672     211155479   2.614792   1.863943  ...        16.970563       1.200050      EA
797     206117559  12.509651  11.861794  ...         4.123106       0.075423  OTHPER
311     206482854   0.386842   0.108125  ...        23.430749       0.356539      EB

[1697 rows x 25 columns]
Predictions:
[[1.50602410e-03 0.00000000e+00 0.00000000e+00 ... 3.27985714e-01
  6.70508262e-01 0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 9.34066667e-01
  6.59333333e-02 0.00000000e+00]
 [2.00000000e-03 4.00000000e-03 3.65016502e-03 ... 6.02733333e-01
  3.83616502e-01 0.00000000e+00]
 ...
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 5.31421429e-01
  4.68578571e-01 0.00000000e+00]
 [5.08753795e-04 0.00000000e+00 0.00000000e+00 ... 7.34497968e-01
  2.61668903e-01 0.00000000e+00]
 [0.00000000e+00 1.07330267e-01 4.47226949e-03 ... 7.46201729e-01
  1.41995734e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=39).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1571    210646889  17.395973  16.500795  ...        15.033296       2.378088   Noise
913     206054167  13.454450  12.809487  ...         7.071068       0.245735  OTHPER
920     211034942   6.115610   6.460617  ...        12.041595       1.280716  OTHPER
1511    210889123  16.500795  10.536584  ...        18.027756       2.366501   Noise
1111    206378264  11.277736  11.950206  ...        14.035669       1.877506  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
1166    210986554  18.607322  17.586791  ...        17.262677       1.430110  OTHPER
991     206133660   6.234515   5.071083  ...        15.297059       2.054563  OTHPER
324     205971103   0.275595   0.091863  ...        22.671568       0.712217      EB
379     210681941   0.618040   0.175528  ...        19.416488       0.126284    RRab
271     205943009   2.919521   1.384344  ...         8.062258       0.060883    GDOR

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.50213333 0.49786667 0.        ]
 [0.         0.         0.         ... 0.82543909 0.17133333 0.        ]
 [0.         0.         0.         ... 0.51343333 0.47672165 0.002     ]
 ...
 [0.         0.         0.         ... 0.61527143 0.38313113 0.        ]
 [0.         0.         0.         ... 0.62992143 0.37007857 0.        ]
 [0.         0.15012215 0.00751745 ... 0.67986749 0.16249292 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=40).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
519     210925792   0.581292   0.172432  ...        21.023796       0.063724    RRab
484     210370729   1.086185   0.362068  ...        24.207437       0.184855      EB
377     210822691   8.073717   0.672760  ...        19.235384       0.853103      EA
827     210482495   1.182230   1.117932  ...         1.000000       0.046168  OTHPER
295     205978103   0.642970   0.214283  ...        23.600847       0.960718      EB
...           ...        ...        ...  ...              ...            ...     ...
819     205956919  13.684117  18.607322  ...        15.000000       1.278574  OTHPER
1444    210727913   9.258795  17.586791  ...        15.132746       1.198289   Noise
1422    210409766  16.006586  15.101961  ...        16.031220       1.271457   Noise
1370    211053637  20.000000  12.707958  ...        14.866069       1.163258   Noise
1053    210964159   3.424645   3.609692  ...        19.924859       0.258969  OTHPER

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.36673096 0.62664286 0.        ]
 [0.002      0.         0.         ... 0.86283333 0.13516667 0.        ]
 [0.         0.         0.         ... 0.51197398 0.48442857 0.        ]
 ...
 [0.002      0.         0.         ... 0.60169762 0.39630238 0.        ]
 [0.         0.         0.         ... 0.68660714 0.31339286 0.        ]
 [0.         0.16683394 0.00828961 ... 0.40236766 0.42250879 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=41).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
713     211007532  20.000000  18.825808  ...         5.656854       0.306689  OTHPER
1368    210867515  16.332702  17.209250  ...        18.027756       1.884310   Noise
349     206382857   0.331180   0.356592  ...         2.000000       0.071072    GDOR
277     206145148   0.060281   0.050363  ...         5.000000       0.144293   DSCUT
901     211009081  12.039946  18.607322  ...        16.031220       0.956537  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
629     210793743   1.136152   0.189332  ...        17.492856       0.273471      EA
1617    210763529  20.000000  18.825808  ...        15.033296       2.629854   Noise
262     206185368   0.608886   0.174762  ...        21.540659       0.095331    RRab
1054    210793570  14.167804  17.981269  ...         6.082763       0.721810  OTHPER
649     210912256   0.049290   0.076122  ...        10.049876       0.904446   DSCUT

[1697 rows x 25 columns]
Predictions:
[[7.60575623e-04 0.00000000e+00 0.00000000e+00 ... 5.18847619e-01
  4.79401850e-01 0.00000000e+00]
 [3.80288462e-03 0.00000000e+00 0.00000000e+00 ... 8.12430449e-01
  1.73766667e-01 0.00000000e+00]
 [0.00000000e+00 1.32283465e-03 2.00000000e-03 ... 3.56057143e-01
  6.34321640e-01 0.00000000e+00]
 ...
 [0.00000000e+00 2.00000000e-03 0.00000000e+00 ... 6.69964286e-01
  3.28035714e-01 0.00000000e+00]
 [1.25638525e-03 1.72813488e-03 1.01547988e-03 ... 7.47276190e-01
  2.48723810e-01 0.00000000e+00]
 [0.00000000e+00 1.03314438e-01 3.51745068e-03 ... 7.83498266e-01
  1.09669846e-01 0.00000000e+00]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=42).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1557    205924593  14.043705  18.393849  ...        11.401754       1.115079   Noise
832     206154674  17.395973  18.393849  ...        18.788294       0.863625  OTHPER
1311    210794850  19.753588   5.323656  ...        15.297059       1.303572   Noise
172     203127694   0.908300   0.956528  ...        11.661904       0.232987    GDOR
564     210815465   0.521370   0.086899  ...        21.540659       0.690505    RRab
...           ...        ...        ...  ...              ...            ...     ...
1037    210577657  11.357627   7.382861  ...        15.000000       1.403027  OTHPER
1589    210905495  17.781843  16.847578  ...        10.198039       1.677293   Noise
617     210835735   0.429829   0.143277  ...        26.248809       0.393385      EB
1654    210680151  20.000000  18.825808  ...        13.928388       0.661545   Noise
1505    206233780  19.278542  18.185219  ...        19.026298       2.336464   Noise

[1697 rows x 25 columns]
Predictions:
[[0.004606   0.         0.         ... 0.45893838 0.53131667 0.        ]
 [0.         0.         0.         ... 0.86549047 0.13073333 0.        ]
 [0.         0.         0.         ... 0.58026105 0.41561603 0.        ]
 ...
 [0.         0.         0.         ... 0.6317     0.3683     0.        ]
 [0.00120773 0.00331926 0.         ... 0.59489874 0.39712289 0.        ]
 [0.         0.13768423 0.00230281 ... 0.68739322 0.1710223  0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=43).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1221    210471622  16.672383  15.848364  ...        19.313208       0.734781   Noise
1649    210814096  20.000000   7.057861  ...        15.652476       0.705950   Noise
950     206260321   5.169181   4.915607  ...        18.000000       0.192027  OTHPER
548     211065427   0.362806   0.848681  ...        15.811388       0.212568    GDOR
1054    206096283  11.861794  19.513174  ...        12.041595       0.919377  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
1050    210554748   0.286807  12.912652  ...        11.000000       0.864111  OTHPER
1056    210855521  18.185219  17.209250  ...        18.973666       0.795878  OTHPER
698     206058994  14.961038  15.848364  ...        12.369317       0.084419  OTHPER
142     205557744   1.360939   0.180305  ...        25.612497       0.852629      EB
497     210374056   0.068808   0.063396  ...        10.000000       0.236695   DSCUT

[1697 rows x 25 columns]
Predictions:
[[0.         0.0011274  0.         ... 0.4968726  0.502      0.        ]
 [0.00121154 0.         0.         ... 0.77053732 0.21646667 0.        ]
 [0.00150602 0.         0.00088028 ... 0.47653333 0.51958335 0.        ]
 ...
 [0.         0.         0.         ... 0.76857143 0.23142857 0.        ]
 [0.         0.00425479 0.         ... 0.79563309 0.19851468 0.        ]
 [0.         0.21904997 0.00688028 ... 0.4541005  0.31819305 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=44).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1582    211122284  14.553620  15.391923  ...        12.041595       1.018511   Noise
1683    210786134  16.006586  17.026494  ...        14.142136       1.169754   Noise
946     211095259   6.817762   7.184366  ...         9.219544       1.382950  OTHPER
73      203463506   0.695851   0.231953  ...        25.495098       0.196496      EB
1612    210418307  19.049485  17.981269  ...         9.486833       0.858510   Noise
...           ...        ...        ...  ...              ...            ...     ...
1548    206108630  20.000000  12.412801  ...        11.401754       0.741374   Noise
219     206353974   0.901152   0.798788  ...         8.062258       0.263519    GDOR
118     203868608   4.547301   5.583198  ...        18.357560       0.742802      EA
855     206116448  12.707958  13.454450  ...        18.867962       0.421634  OTHPER
340     206058387   0.375472   0.125158  ...        24.207437       0.178083      EB

[1697 rows x 25 columns]
Predictions:
[[0.00254821 0.         0.         ... 0.32620952 0.67124227 0.        ]
 [0.00334048 0.00463852 0.00151745 ... 0.73687904 0.25002706 0.        ]
 [0.00120773 0.002      0.002      ... 0.50739393 0.4790645  0.        ]
 ...
 [0.         0.         0.         ... 0.61262857 0.38737143 0.        ]
 [0.         0.002      0.         ... 0.7107381  0.2872619  0.        ]
 [0.         0.13538214 0.00869721 ... 0.63987714 0.21604351 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=45).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
513     210390215   0.056199   0.049175  ...         4.000000       0.186794   DSCUT
226     206409426   0.574419   0.171877  ...        20.615528       0.129272    RRab
1594    210396444  18.393849  17.395973  ...         8.602325       1.218070   Noise
1453    206539360  11.604237  11.044669  ...        14.000000       1.564016   Noise
1023    211152708  12.509651  13.232365  ...        18.248288       2.670352  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
253     205964285   0.899929   0.158693  ...        22.803509       0.409199      EB
920     206412251  19.753588  18.607322  ...        12.165525       0.234347  OTHPER
1537    206250444  15.848364  12.317439  ...        11.180340       1.130350   Noise
1466    210784966  16.006586  15.101961  ...         6.324555       0.209942   Noise
1646    210914569  17.209250  13.684117  ...        16.031220       2.911561   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.42399048 0.57400952 0.        ]
 [0.00320773 0.         0.         ... 0.81999227 0.17220654 0.        ]
 [0.         0.         0.         ... 0.5169     0.47777021 0.        ]
 ...
 [0.         0.         0.         ... 0.76425476 0.23441545 0.        ]
 [0.         0.00158983 0.002      ... 0.75360789 0.2414725  0.        ]
 [0.         0.16107083 0.00591937 ... 0.65439079 0.17861901 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=46).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
890     210605970  15.391923  16.332702  ...        11.401754       0.614823  OTHPER
584     210810961   0.056990   0.067726  ...         3.605551       0.133300   DSCUT
1389    211079188   0.174915   0.158442  ...        19.026298       0.179132   Noise
384     210876158   0.463102   0.154369  ...        24.839485       0.543738      EB
962     210487558  16.168000  12.912652  ...        16.000000       1.911777  OTHPER
...           ...        ...        ...  ...              ...            ...     ...
11      201607088   0.530879   0.044240  ...        24.839485       0.339721      EB
1       201893576   0.929943  13.801916  ...        20.591260       0.292683      EA
940     210770902  20.000000   5.743195  ...        18.027756       1.542862  OTHPER
693     210697426   0.543276   0.090545  ...        20.124612       0.113288    RRab
427     210738738   0.348613  11.604237  ...        20.518285       0.299605      EB

[1697 rows x 25 columns]
Predictions:
[[0.00584843 0.         0.         ... 0.34458571 0.64756586 0.        ]
 [0.         0.00131926 0.         ... 0.84670831 0.14837498 0.        ]
 [0.         0.         0.         ... 0.54593333 0.45406667 0.        ]
 ...
 [0.         0.         0.         ... 0.65078333 0.34921667 0.        ]
 [0.00120773 0.         0.         ... 0.71615894 0.28263333 0.        ]
 [0.         0.1369521  0.00536073 ... 0.66551951 0.19216766 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=47).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1296    206321891  20.000000  18.825808  ...        12.165525       1.215681   Noise
940     210415192   3.824983   3.642495  ...         6.403124       0.182183  OTHPER
1048    210680434  14.686938  19.513174  ...         6.324555       0.839057  OTHPER
15      201780233   0.573597   0.095621  ...        21.540659       0.083801    RRab
1622    210460331  20.000000  18.825808  ...         7.071068       0.735461   Noise
...           ...        ...        ...  ...              ...            ...     ...
895     210717423  17.586791  16.672383  ...        12.806248       0.274529  OTHPER
1625    205926146  20.000000  18.825808  ...         9.000000       0.706574   Noise
230     206189858   0.044551   0.042347  ...         4.000000       0.114636   DSCUT
23      201266727   0.281597   0.051711  ...        24.839485       0.146093      EB
1209    206096568  20.000000  14.961038  ...        14.035669       1.129684   Noise

[1697 rows x 25 columns]
Predictions:
[[0.         0.         0.         ... 0.23430476 0.76169524 0.        ]
 [0.00314224 0.         0.         ... 0.85883589 0.13384845 0.        ]
 [0.         0.002      0.         ... 0.60759048 0.38640952 0.        ]
 ...
 [0.         0.         0.         ... 0.45599048 0.54400952 0.        ]
 [0.00160514 0.         0.         ... 0.66901905 0.32937582 0.        ]
 [0.         0.14930944 0.01343948 ... 0.51693655 0.32031453 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=48).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
1192    210763545  14.422701  15.245563  ...        14.560220       1.682303  OTHPER
1534    210987741  11.688837  14.294117  ...        18.601075       1.849304   Noise
986     211080412   2.011251  17.781843  ...        16.124515       0.218728  OTHPER
58      201832116   1.205338   1.002585  ...         9.219544       0.170611    GDOR
1498    206124863  15.101961  14.294117  ...        14.866069       1.827022   Noise
...           ...        ...        ...  ...              ...            ...     ...
1259    210637769   9.707258   9.205634  ...        10.816654       0.549326   Noise
991     210617105   5.826682   5.253876  ...        16.401219       1.677070  OTHPER
78      203692906   0.701612   0.104407  ...        21.470911       0.042183    RRab
176     205278742   0.058295   0.052729  ...         2.828427       0.076121   DSCUT
240     206131351   0.604981   1.928978  ...        21.540659       0.057370    RRab

[1697 rows x 25 columns]
Predictions:
[[0.00191048 0.         0.00122249 ... 0.41820036 0.57573944 0.        ]
 [0.         0.         0.         ... 0.86412771 0.13273333 0.        ]
 [0.00267385 0.004      0.00254099 ... 0.35088848 0.63561877 0.        ]
 ...
 [0.         0.         0.         ... 0.70185714 0.29814286 0.        ]
 [0.         0.         0.         ... 0.67006069 0.32660952 0.        ]
 [0.         0.20223056 0.006      ... 0.32878371 0.46298573 0.        ]]
Downsampling OTHPER and Noise to 500 members using df.sample(random_state=49).
Down-Sampled Training Set:
      epic_number   Period_1   Period_2  ...  GDOR_DSCUT_dist  template_dist   class
624     210378102   0.464164   0.421680  ...        14.422205       0.119546    GDOR
1390    206107225  11.277736  11.950206  ...        11.045361       0.737558   Noise
346     206314169   0.585324   0.536729  ...         5.000000       0.126937    GDOR
548     211065427   0.362806   0.848681  ...        15.811388       0.212568    GDOR
1239    206461893  20.000000  12.412801  ...        12.649111       1.186586   Noise
...           ...        ...        ...  ...              ...            ...     ...
383     211135076   0.536191   0.564708  ...         6.708204       0.135698    GDOR
1268    210794167  12.707958  13.454450  ...        13.038405       1.528241   Noise
1544    210548604  17.395973  16.500795  ...        12.165525       1.811580   Noise
979     206069797  14.294117  15.101961  ...         4.123106       0.102391  OTHPER
648     210412360   0.105507   1.407433  ...         9.219544       0.525792    GDOR

[1697 rows x 25 columns]
Predictions:
[[0.00171821 0.         0.         ... 0.4379     0.55700814 0.        ]
 [0.00350602 0.         0.         ... 0.86381064 0.12468333 0.        ]
 [0.         0.         0.         ... 0.47596922 0.51483589 0.        ]
 ...
 [0.         0.         0.         ... 0.64303333 0.35696667 0.        ]
 [0.         0.         0.         ... 0.60430238 0.39569762 0.        ]
 [0.         0.19281178 0.01101195 ... 0.53399871 0.26217756 0.        ]]
FINAL PREDICTIONS
        epic_number  Campaign     DSCUT  ...    OTHPER      RRab   Class
0         211827783         5  0.002098  ...  0.589898  0.000000  OTHPER
1         211953842         5  0.001965  ...  0.168066  0.000000   Noise
2         211935903         5  0.000947  ...  0.506504  0.000098  OTHPER
3         212131093         5  0.003819  ...  0.461022  0.000000   Noise
4         211752867         5  0.000126  ...  0.034828  0.000000   Noise
...             ...       ...       ...  ...       ...       ...     ...
101107    228723305        10  0.000783  ...  0.425461  0.000067   Noise
101108    201621810        10  0.000605  ...  0.174955  0.000000   Noise
101109    201265774        10  0.000546  ...  0.336787  0.000000   Noise
101110    228752576        10  0.001128  ...  0.289247  0.000000   Noise
101111    229081521        10  0.000156  ...  0.244261  0.000000   Noise

[101112 rows x 10 columns]
Written to file.
